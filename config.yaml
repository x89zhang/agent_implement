# Unified LangGraph agent configuration example

llm:
  provider: "mock"         # mock | openai | anthropic | vllm_openai
  model: "qwen2.5-7b"
  temperature: 0.2
  base_url: "http://localhost:8000/v1"             # optional, e.g. http://localhost:8000/v1 for vLLM (OpenAI-compatible)
  api_key: ""              # optional, leave empty to use env vars

agent:
  name: "demo-agent"
  system_prompt: |
    You are a configurable assistant. Please answer concisely.
  task: "Describe your capabilities briefly."

tools:
  - name: "calculator"
    import: "agent_scaffold.tools:calculator"
    description: "Safe arithmetic calculator, input like: 1+2*3"

graph:
  type: "single_agent"
  max_iters: 4
  tool_call_format: "TOOL_CALL: <name> <json>"
  stop_keyword: "FINAL"

monitoring:
  enabled: true
  output_path: "trace.json"
