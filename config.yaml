# Unified LangGraph agent configuration example

llm:
  provider: "vllm_openai"         # mock | openai | anthropic | vllm_openai
  model: "qwen2.5-7b"
  temperature: 0.2
  base_url: "http://localhost:8000/v1"             # optional, e.g. http://localhost:8000/v1 for vLLM (OpenAI-compatible)
  api_key: ""              # optional, leave empty to use env vars

agent:
  name: "demo-agent"
  system_prompt: |
    You are a configurable assistant. Please answer concisely.
  task: "Help me to calculate 100+100"

tools:
  - name: "calculator"
    import: "agent_scaffold.tools:calculator"
    description: "Safe arithmetic calculator, input like: 1+2*3"

graph:
  type: "langchain_react"     # single_agent | langchain_react
  max_iters: 4
  tool_call_format: "TOOL_CALL: <name> <json>"
  stop_keyword: "FINAL"
  react_prompt: ""          # Optional ReAct prompt template with {tools} {tool_names} {input} {agent_scratchpad}

monitoring:
  enabled: true
  output_path: "trace.json"
